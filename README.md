Cook County Document Pipeline

ğŸš€ Overview



The Cook County Document Pipeline is a fully automated, multi-phase scraping and data processing system designed to collect, process, and enrich public records from Cook County websites.



This pipeline is state-aware, idempotent, and safe to run daily.

It automatically detects previously processed records and exits early when no new data is available.



Once configured, the pipeline can run unattended on macOS using system scheduling.



ğŸ§  Key Features



âœ… Multi-phase execution (Phase 1 â†’ Phase 4)



âœ… Automatic continuation between phases



âœ… Duplicate detection across CSV, JSON, and filesystem



âœ… PDF downloading and OCR extraction



âœ… Case status enrichment via court search



âœ… Centralized Excel output (multiple sheets)



âœ… Incremental saving (crash-safe)



âœ… Daily automation support (launchd)



âœ… No manual intervention required after setup



ğŸ§© Pipeline Architecture



Phase 1 â†’ Phase 2 â†’ Phase 3 â†’ Phase 4

&nbsp;  â”‚         â”‚         â”‚         â”‚

&nbsp;  â–¼         â–¼         â–¼         â–¼

&nbsp;CSV/JSON  PDFs     OCR Data   Case Status



Each phase only runs if necessary.

If all data has already been processed, the pipeline exits automatically.



ğŸ”„ Phase Breakdown

Phase 1 â€” Document Index Scraper



File: phase1\_scraper.py



Scrapes Cook County document listings by date range



Saves:



phase1\_results.csv



phase1\_results.json



Detects previously scraped document numbers



Stops automatically when no new records exist



Phase 2 â€” Document Detail Scraper \& PDF Downloader



File: phase2\_scraper.py



Loads results from Phase 1



Scrapes document detail pages



Downloads associated PDFs



Saves:



phase2\_results.csv



phase2\_results.json



PDFs into /pdf directory



Skips documents already processed



Phase 3 â€” OCR \& Data Extraction



File: phase3\_results.py



Performs OCR on downloaded PDFs



Extracts:



Case numbers



Dollar amounts



Property addresses



Uses multi-pass OCR for watermark-heavy documents



Saves:



phase3\_results.csv



phase3\_results.json



Prevents duplicate case processing



Phase 4 â€” Case Status Enrichment



File: phase4\_results.py



Searches Cook County court records by case number



Determines foreclosure or dismissal status



Assigns color-coded tags



Saves:



phase4\_results.csv



phase4\_results.json



Includes:



User-agent rotation



Viewport randomization



Rate limiting



ğŸ§  Central Orchestration

run\_pipeline.py



This is the single entry point for the entire system



python run\_pipeline.py



What it does:



Runs Phase 1 until completion or early exit



Automatically triggers Phase 2



Then Phase 3



Then Phase 4



Consolidates results into a single Excel file:



centralized\_results.xlsx



One sheet per phase



You never run individual phases manually in production.



ğŸ“Š Output Files



Generated automatically on first run:



phase1\_results.csv / .json

phase2\_results.csv / .json

phase3\_results.csv / .json

phase4\_results.csv / .json

centralized\_results.xlsx

pdf/



All files are saved in the project root directory.



ğŸ–¥ï¸ System Requirements

macOS (Recommended)



Python 3.10+

Playwright

Tesseract OCR

Poppler (PDF rendering)

Required System Tools



brew install python

brew install tesseract

brew install poppler



ğŸ“¦ Python Dependencies



Installed automatically via pip:



playwright

pandas

openpyxl

pytesseract

pdf2image

pillow

requests



âš™ï¸ Setup Instructions (macOS)



git clone https://github.com/YOUR\_USERNAME/cook-county-document-pipeline.git

cd cook-county-document-pipeline



python3 -m venv venv

source venv/bin/activate



pip install -r requirements.txt

playwright install



python run\_pipeline.py



â±ï¸ Daily Automation (macOS)



This pipeline is designed to be safely run once per day using launchd.



Automatically exits if no new data exists

Safe to run unattended

Logs output to file

(See /docs/automation.md if included)



ğŸ›‘ Important Notes



This project scrapes publicly accessible records

Cloudflare human verification may require manual intervention

Designed for research and data analysis purposes

Respect website terms of service



ğŸ§ª Development Notes



Each phase is intentionally independent

CSV + JSON outputs are written incrementally

The pipeline is crash-resilient by design

Safe to stop and restart at any point



ğŸ“„ License



MIT License (recommended)



ğŸ‘¤ Author



Built by \[Your Name]



Automation-focused, state-aware scraping pipeline for structured public records.

